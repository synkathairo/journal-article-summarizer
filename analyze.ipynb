{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():\n",
    "\tdevice = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# arxiv_abstracts_2021 = load_dataset(\"gfissore/arxiv-abstracts-2021\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0704.0001',\n",
       " 'submitter': 'Pavel Nadolsky',\n",
       " 'authors': \"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\",\n",
       " 'title': 'Calculation of prompt diphoton production cross sections at Tevatron and\\n  LHC energies',\n",
       " 'comments': '37 pages, 15 figures; published version',\n",
       " 'journal-ref': 'Phys.Rev.D76:013009,2007',\n",
       " 'doi': '10.1103/PhysRevD.76.013009',\n",
       " 'abstract': '  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n',\n",
       " 'report-no': 'ANL-HEP-PR-07-12',\n",
       " 'categories': ['hep-ph'],\n",
       " 'versions': ['v1', 'v2']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arxiv_abstracts_2021[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "arxiv_summarization = load_dataset(\"ccdv/arxiv-summarization\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': 'additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \\n it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . \\n many examples of such estimators belong to the large class of regularized kernel based methods over a reproducing kernel hilbert space @xmath0 , see e.g. @xcite . in the last years \\n many interesting results on learning rates of regularized kernel based models for additive models have been published when the focus is on sparsity and when the classical least squares loss function is used , see e.g. @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and the references therein . of course , the least squares loss function is differentiable and has many nice mathematical properties , but it is only locally lipschitz continuous and therefore regularized kernel based methods based on this loss function typically suffer on bad statistical robustness properties , even if the kernel is bounded . \\n this is in sharp contrast to kernel methods based on a lipschitz continuous loss function and on a bounded loss function , where results on upper bounds for the maxbias bias and on a bounded influence function are known , see e.g. @xcite for the general case and @xcite for additive models . \\n therefore , we will here consider the case of regularized kernel based methods based on a general convex and lipschitz continuous loss function , on a general kernel , and on the classical regularizing term @xmath1 for some @xmath2 which is a smoothness penalty but not a sparsity penalty , see e.g. @xcite . \\n such regularized kernel based methods are now often called support vector machines ( svms ) , although the notation was historically used for such methods based on the special hinge loss function and for special kernels only , we refer to @xcite .    in this paper we address the open question , whether an svm with an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , if the assumption of an additive model is satisfied . \\n our leading example covers learning rates for quantile regression based on the lipschitz continuous but non - differentiable pinball loss function , which is also called check function in the literature , see e.g. @xcite and @xcite for parametric quantile regression and @xcite , @xcite , and @xcite for kernel based quantile regression . \\n we will not address the question how to check whether the assumption of an additive model is satisfied because this would be a topic of a paper of its own . \\n of course , a practical approach might be to fit both models and compare their risks evaluated for test data . \\n for the same reason we will also not cover sparsity . \\n consistency of support vector machines generated by additive kernels for additive models was considered in @xcite . in this paper \\n we establish learning rates for these algorithms . \\n let us recall the framework with a complete separable metric space @xmath3 as the input space and a closed subset @xmath4 of @xmath5 as the output space . \\n a borel probability measure @xmath6 on @xmath7 is used to model the learning problem and an independent and identically distributed sample @xmath8 is drawn according to @xmath6 for learning . \\n a loss function @xmath9 is used to measure the quality of a prediction function @xmath10 by the local error @xmath11 . \\n _ throughout the paper we assume that @xmath12 is measurable , @xmath13 , convex with respect to the third variable , and uniformly lipschitz continuous satisfying @xmath14 with a finite constant @xmath15 . \\n _    support vector machines ( svms ) considered here are kernel - based regularization schemes in a reproducing kernel hilbert space ( rkhs ) @xmath0 generated by a mercer kernel @xmath16 . with a shifted loss function @xmath17 introduced for dealing \\n even with heavy - tailed distributions as @xmath18 , they take the form @xmath19 where for a general borel measure @xmath20 on @xmath21 , the function @xmath22 is defined by @xmath23 where @xmath24 is a regularization parameter . \\n the idea to shift a loss function has a long history , see e.g. @xcite in the context of m - estimators . \\n it was shown in @xcite that @xmath22 is also a minimizer of the following optimization problem involving the original loss function @xmath12 if a minimizer exists : @xmath25    the additive model we consider consists of the _ input space decomposition _ \\n @xmath26 with each @xmath27 a complete separable metric space and a _ hypothesis space _ \\n @xmath28 where @xmath29 is a set of functions @xmath30 each of which is also identified as a map @xmath31 from @xmath3 to @xmath5 . \\n hence the functions from @xmath32 take the additive form @xmath33 . \\n we mention , that there is strictly speaking a notational problem here , because in the previous formula each quantity @xmath34 is an element of the set @xmath35 which is a subset of the full input space @xmath36 , @xmath37 , whereas in the definition of sample @xmath8 each quantity @xmath38 is an element of the full input space @xmath36 , where @xmath39 . \\n because these notations will only be used in different places and because we do not expect any misunderstandings , we think this notation is easier and more intuitive than specifying these quantities with different symbols . \\n the additive kernel @xmath40 is defined in terms of mercer kernels @xmath41 on @xmath27 as @xmath42 it generates an rkhs @xmath0 which can be written in terms of the rkhs @xmath43 generated by @xmath41 on @xmath27 corresponding to the form ( [ additive ] ) as @xmath44 with norm given by @xmath45 the norm of @xmath46 satisfies @xmath47    to illustrate advantages of additive models , we provide two examples of comparing additive with product kernels . \\n the first example deals with gaussian rbf kernels . \\n all proofs will be given in section [ proofsection ] . \\n [ gaussadd ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and @xmath52.\\\\ ] ] the additive kernel @xmath53 is given by @xmath54 furthermore , the product kernel @xmath55 is the standard gaussian kernel given by @xmath56 define a gaussian function @xmath57 on @xmath58 ^ 2 $ ] depending only on one variable by @xmath59 then @xmath60 but @xmath61 where @xmath62 denotes the rkhs generated by the standard gaussian rbf kernel @xmath63 . \\n the second example is about sobolev kernels . \\n [ sobolvadd ] let @xmath64 , @xmath65 $ ] and @xmath58^s.$ ] let @xmath66 : = \\\\bigl\\\\{u\\\\in l_2([0,1 ] ) ; d^\\\\alpha u \\\\in l_2([0,1 ] ) \\\\mbox{~for~all~}|\\\\alpha|\\\\le 1\\\\bigr\\\\}\\\\ ] ] be the sobolev space consisting of all square integrable univariate functions whose derivative is also square integrable . \\n it is an rkhs with a mercer kernel @xmath67 defined on @xmath68 ^ 2 $ ] . \\n if we take all the mercer kernels @xmath69 to be @xmath67 , then @xmath70 $ ] for each @xmath71 . \\n the additive kernel @xmath72 is also a mercer kernel and defines an rkhs @xmath73\\\\right\\\\}.\\\\ ] ] however , the multivariate sobolev space @xmath74^s)$ ] , consisting of all square integrable functions whose partial derivatives are all square integrable , contains discontinuous functions and is not an rkhs . \\n denote the marginal distribution of @xmath6 on @xmath27 as @xmath75 . under the assumption that @xmath76 for each @xmath71 and that @xmath43 is dense in @xmath29 in the @xmath77-metric , it was proved in @xcite that @xmath78 in probability as long as @xmath79 satisfies @xmath80 and @xmath81 . \\n the rest of the paper has the following structure . \\n section [ ratessection ] contains our main results on learning rates for svms based on additive kernels . learning rates for quantile regression \\n are treated as important special cases . \\n section [ comparisonsection ] contains a comparison of our results with other learning rates published recently . \\n section [ proofsection ] contains all the proofs and some results which can be interesting in their own . \\n in this paper we provide some learning rates for the support vector machines generated by additive kernels for additive models which helps improve the quantitative understanding presented in @xcite . \\n the rates are about asymptotic behaviors of the excess risk @xmath82 and take the form @xmath83 with @xmath84 . \\n they will be stated under three kinds of conditions involving the hypothesis space @xmath0 , the measure @xmath6 , the loss @xmath12 , and the choice of the regularization parameter @xmath85 . \\n the first condition is about the approximation ability of the hypothesis space @xmath0 . \\n since the output function @xmath19 is from the hypothesis space , the learning rates of the learning algorithm depend on the approximation ability of the hypothesis space @xmath0 with respect to the optimal risk @xmath86 measured by the following approximation error . \\n [ defapprox ] the approximation error of the triple @xmath87 is defined as @xmath88    to estimate the approximation error , we make an assumption about the minimizer of the risk @xmath89    for each @xmath90 , define the integral operator @xmath91 associated with the kernel @xmath41 by @xmath92 we mention that @xmath93 is a compact and positive operator on @xmath94 . hence we can find its normalized eigenpairs @xmath95 such that @xmath96 is an orthonormal basis of @xmath94 and @xmath97 as @xmath98 . fix @xmath99 . \\n then we can define the @xmath100-th power @xmath101 of @xmath93 by @xmath102 this is a positive and bounded operator and its range is well - defined . \\n the assumption @xmath103 means @xmath104 lies in this range . \\n [ assumption1 ] we assume @xmath105 and @xmath106 where for some @xmath107 and each @xmath108 , @xmath109 is a function of the form @xmath110 with some @xmath111 . \\n the case @xmath112 of assumption [ assumption1 ] means each @xmath113 lies in the rkhs @xmath43 . \\n a standard condition in the literature ( e.g. , @xcite ) for achieving decays of the form @xmath114 for the approximation error ( [ approxerrordef ] ) is @xmath115 with some @xmath116 . here \\n the operator @xmath117 is defined by @xmath118 in general , this can not be written in an additive form . \\n however , the hypothesis space ( [ additive ] ) takes an additive form @xmath119 . \\n so it is natural for us to impose an additive expression @xmath120 for the target function @xmath121 with the component functions @xmath113 satisfying the power condition @xmath110 . \\n the above natural assumption leads to a technical difficulty in estimating the approximation error : the function @xmath113 has no direct connection to the marginal distribution @xmath122 projected onto @xmath27 , hence existing methods in the literature ( e.g. , @xcite ) can not be applied directly . \\n note that on the product space @xmath123 , there is no natural probability measure projected from @xmath6 , and the risk on @xmath124 is not defined .    our idea to overcome the difficulty is to introduce an intermediate function @xmath125 . \\n it may not minimize a risk ( which is not even defined ) . \\n however , it approximates the component function @xmath113 well . \\n when we add up such functions @xmath126 , we get a good approximation of the target function @xmath121 , and thereby a good estimate of the approximation error . \\n this is the first novelty of the paper . \\n [ approxerrorthm ] under assumption [ assumption1 ] , we have @xmath127 where @xmath128 is the constant given by @xmath129      the second condition for our learning rates is about the capacity of the hypothesis space measured by @xmath130-empirical covering numbers .    let @xmath131 be a set of functions on @xmath21 and @xmath132 for every @xmath133 the * covering number of @xmath131 * with respect to the empirical metric @xmath134 , given by @xmath135 is defined as @xmath136 and the * @xmath130-empirical covering number * of @xmath137 is defined as @xmath138    [ assumption2 ] we assume @xmath139 and that for some @xmath140 , @xmath141 and every @xmath142 , the @xmath130-empirical covering number of the unit ball of @xmath43 satisfies @xmath143    the second novelty of this paper is to observe that the additive nature of the hypothesis space yields the following nice bound with a dimension - independent power exponent for the covering numbers of the balls of the hypothesis space @xmath0 , to be proved in section [ samplesection ] . \\n [ capacitythm ] under assumption [ assumption2 ] , for any @xmath144 and @xmath145 , we have @xmath146    the bound for the covering numbers stated in theorem [ capacitythm ] is special : the power @xmath147 is independent of the number @xmath148 of the components in the additive model . \\n it is well - known @xcite in the literature of function spaces that the covering numbers of balls of the sobolev space @xmath149 on the cube @xmath150^s$ ] of the euclidean space @xmath151 with regularity index @xmath152 has the following asymptotic behavior with @xmath153 : @xmath154 here the power @xmath155 depends linearly on the dimension @xmath148 . \\n similar dimension - dependent bounds for the covering numbers of the rkhss associated with gaussian rbf - kernels can be found in @xcite . \\n the special bound in theorem [ capacitythm ] demonstrates an advantage of the additive model in terms of capacity of the additive hypothesis space . \\n the third condition for our learning rates is about the noise level in the measure @xmath6 with respect to the hypothesis space . before stating the general condition \\n , we consider a special case for quantile regression , to illustrate our general results . \\n let @xmath156 be a quantile parameter . \\n the quantile regression function @xmath157 is defined by its value @xmath158 to be a @xmath159-quantile of @xmath160 , i.e. , a value @xmath161 satisfying @xmath162 the regularization scheme for quantile regression considered here takes the form ( [ algor ] ) with the loss function @xmath12 given by the pinball loss as @xmath163    a noise condition on @xmath6 for quantile regression is defined in @xcite as follows . to this end , let @xmath164 be a probability measure on @xmath165 and @xmath166 . then a real number @xmath167 is called @xmath159-quantile of @xmath164 , if and only if @xmath167 belongs to the set @xmath168\\\\bigr ) \\\\ge \\n \\\\tau     \\\\mbox{~~and~~ } q\\\\bigl([t , \\\\infty)\\\\bigr ) \\\\ge 1-\\\\tau\\\\bigr\\\\}\\\\,.\\\\ ] ] it is well - known that @xmath169 is a compact interval . \\n [ noisecond ] let @xmath166 .    1 . \\n a probability measure @xmath164 on @xmath165 is said to have a * @xmath159-quantile of type @xmath170 * , if there exist a @xmath159-quantile @xmath171 and a constant @xmath172 such that , for all @xmath173 $ ] , we have @xmath174 2 . \\n let @xmath175 $ ] . \\n we say that a probability measure @xmath20 on @xmath176 has a * @xmath159-quantile of @xmath177-average type @xmath170 * if the conditional probability measure @xmath178 has @xmath179-almost surely a @xmath159-quantile of type @xmath170 and the function @xmath180 where @xmath181 is the constant defined in part ( 1 ) , satisfies @xmath182 . \\n one can show that a distribution @xmath164 having a @xmath159-quantile of type @xmath170 has a unique @xmath159-quantile @xmath183 . \\n moreover , if @xmath164 has a lebesgue density @xmath184 then @xmath164 has a @xmath159-quantile of type @xmath170 if @xmath184 is bounded away from zero on @xmath185 $ ] since we can use @xmath186\\\\}$ ] in ( [ tauquantileoftype2formula ] ) . \\n this assumption is general enough to cover many distributions used in parametric statistics such as gaussian , student s @xmath187 , and logistic distributions ( with @xmath188 ) , gamma and log - normal distributions ( with @xmath189 ) , and uniform and beta distributions ( with @xmath190 $ ] ) . \\n the following theorem , to be proved in section [ proofsection ] , gives a learning rate for the regularization scheme ( [ algor ] ) in the special case of quantile regression . \\n [ quantilethm ] suppose that @xmath191 almost surely for some constant @xmath192 , and that each kernel @xmath41 is @xmath193 with @xmath194 for some @xmath195 . \\n if assumption [ assumption1 ] holds with @xmath112 and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath198 and @xmath199 , with confidence at least @xmath200 we have @xmath201 where @xmath202 is a constant independent of @xmath203 and @xmath204 and @xmath205    please note that the exponent @xmath206 given by ( [ quantilerates2 ] ) for the learning rate in ( [ quantilerates ] ) is independent of the quantile level @xmath159 , of the number @xmath148 of additive components in @xmath207 , and of the dimensions @xmath208 and @xmath209 further note that @xmath210 , if @xmath211 , and @xmath212 if @xmath213 . because @xmath214 can be arbitrarily close to @xmath215 , the learning rate , which is independent of the dimension @xmath216 and given by theorem [ quantilethm ] , is close to @xmath217 for large values of @xmath177 and is close to @xmath218 or better , if @xmath211 .      to state our general learning rates \\n , we need an assumption on a _ variance - expectation bound _ which is similar to definition [ noisecond ] in the special case of quantile regression . \\n [ assumption3 ] we assume that there exist an exponent @xmath219 $ ] and a positive constant @xmath220 such that @xmath221    assumption [ assumption3 ] always holds true for @xmath222 . if the triple @xmath223 satisfies some conditions , the exponent @xmath224 can be larger . \\n for example , when @xmath12 is the pinball loss ( [ pinloss ] ) and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath225 for some @xmath196 $ ] and @xmath226 as defined in @xcite , then @xmath227 . \\n [ mainratesthm ] suppose that @xmath228 is bounded by a constant @xmath229 almost surely . under assumptions [ assumption1 ] to [ assumption3 ] , \\n if we take @xmath198 and @xmath230 for some @xmath231 , then for any @xmath232 , with confidence at least @xmath200 we have @xmath233 where @xmath234 is given by @xmath235 and @xmath202 is constant independent of @xmath203 or @xmath204 ( to be given explicitly in the proof ) . \\n we now add some theoretical and numerical comparisons on the goodness of our learning rates with those from the literature . as already mentioned in the introduction \\n , some reasons for the popularity of additive models are flexibility , increased interpretability , and ( often ) a reduced proneness of the curse of high dimensions . \\n hence it is important to check , whether the learning rate given in theorem [ mainratesthm ] under the assumption of an additive model favourably compares to ( essentially ) optimal learning rates without this assumption . in other words , \\n we need to demonstrate that the main goal of this paper is achieved by theorem [ quantilethm ] and theorem [ mainratesthm ] , i.e. that an svm based on an additive kernel can provide a substantially better learning rate in high dimensions than an svm with a general kernel , say a classical gaussian rbf kernel , provided the assumption of an additive model is satisfied . \\n our learning rate in theorem [ quantilethm ] is new and optimal in the literature of svm for quantile regression . \\n most learning rates in the literature of svm for quantile regression are given for projected output functions @xmath236 , while it is well known that projections improve learning rates @xcite . here the projection operator @xmath237 is defined for any measurable function @xmath10 by @xmath238 sometimes this is called clipping . \\n such results are given in @xcite . \\n for example , under the assumptions that @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , the approximation error condition ( [ approxerrorb ] ) is satisfied for some @xmath239 , and that for some constants @xmath240 , the sequence of eigenvalues @xmath241 of the integral operator @xmath117 satisfies @xmath242 for every @xmath243 , it was shown in @xcite that with confidence at least @xmath200 , @xmath244 where @xmath245 here the parameter @xmath246 measures the capacity of the rkhs @xmath247 and it plays a similar role as half of the parameter @xmath147 in assumption 2 . for a @xmath193 kernel and @xmath112 \\n , one can choose @xmath246 and @xmath147 to be arbitrarily small and the above power index @xmath248 can be taken as @xmath249 . \\n the learning rate in theorem [ quantilethm ] may be improved by relaxing assumption 1 to a sobolev smoothness condition for @xmath121 and a regularity condition for the marginal distribution @xmath250 . \\n for example , one may use a gaussian kernel @xmath251 depending on the sample size @xmath203 and @xcite achieve the approximation error condition ( [ approxerrorb ] ) for some @xmath252 . \\n this is done for quantile regression in @xcite . \\n since we are mainly interested in additive models , we shall not discuss such an extension . \\n [ gaussmore ] let @xmath48 , @xmath49 $ ] and @xmath50 ^ 2.$ ] let @xmath51 and the additive kernel @xmath72 be given by ( [ gaussaddform ] ) with @xmath253 in example [ gaussadd ] as @xmath52.\\\\ ] ] if the function @xmath121 is given by ( [ gaussfcn ] ) , @xmath191 almost surely for some constant @xmath192 , and @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 for some @xmath196 $ ] , then by taking @xmath197 , for any @xmath145 and @xmath199 , ( [ quantilerates ] ) holds with confidence at least @xmath200 .    it is unknown whether the above learning rate can be derived by existing approaches in the literature ( e.g. @xcite ) even after projection . \\n note that the kernel in the above example is independent of the sample size . \\n it would be interesting to see whether there exists some @xmath99 such that the function @xmath57 defined by ( [ gaussfcn ] ) lies in the range of the operator @xmath254 . \\n the existence of such a positive index would lead to the approximation error condition ( [ approxerrorb ] ) , see @xcite .    let us now add some numerical comparisons on the goodness of our learning rates given by theorem [ mainratesthm ] with those given by @xcite . \\n their corollary 4.12 gives ( essentially ) minmax optimal learning rates for ( clipped ) svms in the context of nonparametric quantile regression using one gaussian rbf kernel on the whole input space under appropriate smoothness assumptions of the target function . \\n let us consider the case that the distribution @xmath6 has a @xmath159-quantile of @xmath177-average type @xmath170 , where @xmath255 , and assume that both corollary 4.12 in @xcite and our theorem [ mainratesthm ] are applicable . \\n i.e. , we assume in particular that @xmath6 is a probability measure on @xmath256 $ ] and that the marginal distribution @xmath257 has a lebesgue density @xmath258 for some @xmath259 . furthermore , suppose that the optimal decision function @xmath260 has ( to make theorem [ mainratesthm ] applicable with @xmath261 $ ] ) the additive structure @xmath207 with each @xmath104 as stated in assumption [ assumption1 ] , where @xmath262 and @xmath263 , with minimal risk @xmath86 and additionally fulfills ( to make corollary 4.12 in @xcite applicable ) @xmath264 where @xmath265 $ ] and @xmath266 denotes a besov space with smoothness parameter @xmath267 . \\n the intuitive meaning of @xmath248 is , that increasing values of @xmath248 correspond to increased smoothness . \\n we refer to ( * ? ? ? * and p. 44 ) for details on besov spaces . \\n it is well - known that the besov space @xmath268 contains the sobolev space @xmath269 for @xmath270 , @xmath271 , and @xmath272 , and that @xmath273 . \\n we mention that if all @xmath41 are suitably chosen wendland kernels , their reproducing kernel hilbert spaces @xmath43 are sobolev spaces , see ( * ? ? ? \\n * thm . 10.35 , p. 160 ) . \\n furthermore , we use the same sequence of regularizing parameters as in ( * ? ? ? \\n 4.9 , cor . 4.12 ) , i.e. , @xmath274 where @xmath275 , @xmath276 , @xmath277 $ ] , and @xmath278 is some user - defined positive constant independent of @xmath279 . for \\n reasons of simplicity , let us fix @xmath280 . \\n then ( * ? ? ? \\n 4.12 ) gives learning rates for the risk of svms for @xmath159-quantile regression , if a single gaussian rbf - kernel on @xmath281 is used for @xmath159-quantile functions of @xmath177-average type @xmath170 with @xmath255 , which are of order @xmath282 hence the learning rate in theorem [ quantilethm ] is better than the one in ( * ? ? ? \\n 4.12 ) in this situation , if @xmath283 provided the assumption of the additive model is valid . \\n table [ table1 ] lists the values of @xmath284 from ( [ explicitratescz2 ] ) for some finite values of the dimension @xmath216 , where @xmath285 . \\n all of these values of @xmath284 are positive with the exceptions if @xmath286 or @xmath287 . \\n this is in contrast to the corresponding exponent in the learning rate by ( * ? ? \\n * cor . 4.12 ) , because @xmath288    table [ table2 ] and figures [ figure1 ] to [ figure2 ] give additional information on the limit @xmath289 . \\n of course , higher values of the exponent indicates faster rates of convergence . \\n it is obvious , that an svm based on an additive kernel has a significantly faster rate of convergence in higher dimensions @xmath216 compared to svm based on a single gaussian rbf kernel defined on the whole input space , of course under the assumption that the additive model is valid . \\n the figures seem to indicate that our learning rate from theorem [ mainratesthm ] is probably not optimal for small dimensions . however , the main focus of the present paper is on high dimensions . \\n .[table1 ] the table lists the limits of the exponents @xmath290 from ( * ? ? ? \\n * cor . 4.12 ) and @xmath291 from theorem [ mainratesthm ] , respectively , if the regularizing parameter @xmath292 is chosen in an optimal manner for the nonparametric setup , i.e. @xmath293 , with @xmath294 for @xmath295 and @xmath296 . \\n recall that @xmath297 $ ] . \\n [ cols= \" > , > , > , > \" , ]',\n",
       " 'abstract': 'additive models play an important role in semiparametric statistics . \\n this paper gives learning rates for regularized kernel based methods for additive models . \\n these learning rates compare favourably in particular in high dimensions to recent results on optimal learning rates for purely nonparametric regularized kernel based quantile regression using the gaussian radial basis function kernel , provided the assumption of an additive model is valid . \\n additionally , a concrete example is presented to show that a gaussian function depending only on one variable lies in a reproducing kernel hilbert space generated by an additive gaussian kernel , but does not belong to the reproducing kernel hilbert space generated by the multivariate gaussian kernel of the same variance .    * \\n key words and phrases . * additive model , kernel , quantile regression , semiparametric , rate of convergence , support vector machine .'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_summarization[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_summarization = arxiv_summarization.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': \"clusters of galaxies represent unique signposts in the universe , where the physical properties of the cosmic diffuse baryons can be studied in great details and used to trace the past history of cosmic structure formation ( e.g. rosati et al . \\n 2002 ; voit 2005 , for reviews ) . as a result of adiabatic compression and shocks generated by supersonic motion during shell crossing and virialization , \\n a hot thin gas permeating the cluster gravitational potential well is formed . \\n typically this gas , which is enriched with metals ejected form supernovae ( sne ) explosions through subsequent episodes of star formation ( e.g. matteucci & vettolani 1988 ; renzini 1997 ) , reaches temperatures of several @xmath7 k and therefore emits mainly via thermal bremsstrahlung in the x - rays . at such temperatures most of the elements are either fully ionized or in a high ionization state . \\n + particularly evident in x  ray spectra of galaxy clusters are the strong transitions to the @xmath8 level ( k  shell ) of the h  like and he  like ions of iron in the energy range 6.76.9 kev . \\n below 2 kev , @xmath9 level ( l  shell ) transition of iron and @xmath10 elements can be detected , especially in the low temperature region in the centers of the so  called cool core clusters , that are characterized by a strong peak in the surface brightness distribution , and therefore short cooling times . \\n spatially resolved cc clusters show a peak in the metal distribution associated to the low temperature core region ( e.g. de grandi & molendi 2001 and 2002 , hereafter dm01 and dm02 ) . \\n although the amount of energy supplied to the intra - cluster medium ( icm ) by sne explosions depends on several factors ( e.g. the physical condition of the icm at the epoch of the enrichment ) and can not be obtained directly from x  ray observations , the radial distribution of metals , as well as their abundance as a function of time , are crucial information to shed light on the cosmic star formation history and to trace the effect of sn feedback on the icm . \\n + several analyses have been presented in the literature with the aim to study the radial distribution of metals in clusters of galaxies . \\n finoguenov , david & ponman ( 2000 ) performed a spatially resolved x - ray spectroscopic analysis of 11 relaxed clusters observed by rosat and asca , deriving a radial distribution of single heavy elements such as fe , si , ne and s. they found that the total fe abundance decreases significantly with radius in all clusters , while the si , ne and s abundances are either flat or decrease less rapidly . \\n dm01 derived radial metallicity profiles ( mainly driven by fe ) of 17 nearby clusters observed by bepposax . \\n they found a strong enhancement in the abundance in the central regions of the cc clusters . \\n a flatter metallicity profile was observed instead for the non - cool core clusters in their sample . \\n since all the ncc clusters show signs of recent merger activity , they suggested that the merger events may have redistributed efficiently the metal content of the intracluster medium . \\n irwin & bregman ( 2001 ) derived iron - abundance profiles for 12 clusters with @xmath11 observed by beppo sax . \\n although they investigated the differences between cc and ncc clusters in a less systematic way than dm01 , they found a negative gradient in the abundance profiles of all the cc clusters and to a lesser significance also in the ncc clusters . similarly to dm01 , they found that cc clusters have higher metallicity than ncc clusters at every radius . \\n it is worth to say that the aforementioned papers investigated the metallicity trends only within @xmath12 . \\n spatially resolved measures of the metal abundance in galaxy clusters were performed also with xmm - newton . in particular tamura et al . \\n ( 2004 ) analyzed a sample of 19 x - ray bright relaxed clusters , obtaining elemental abundances of fe , si , s and o. they found that while the distribution of fe , si and s is generally peaked toward the center , the o abundances are uniform throughout the cluster , pointing out to a different origin among these metals , most likely in sne ia and ii . \\n more recently vikhlinin et al . \\n ( 2005 ) have derived temperature and metallicity profiles for 11 low - redshift clusters observed by chandra . \\n the clusters in their sample however are all cc clusters , presenting a very regular overall x - ray morphology and showing only very weak signs of dynamical activity . \\n although they have not analyzed the metallicity profiles rescaled to the virial radius of the cluster ( as they did for the temperature profiles ) a negative gradient of @xmath13 is present in all the objects in their sample . \\n however , almost all the spatially - resolved metallicity profiles are measured in local clusters ( @xmath14 ) .    on the other hand , \\n measurements of the metal content of the intracluster medium at high@xmath15 has been obtained with single emission - weighted estimates from chandra and xmm - newton exposures of 56 clusters at @xmath16 in balestra et al . \\n they measured the iron abundance within ( 0.15 - 0.3)@xmath17 and found a negative evolution of @xmath18 with the redsfhift , with clusters at @xmath19 having a constant average fe abundance of @xmath20 , while objects in the redshift range @xmath21 show @xmath18 significantly higher ( @xmath22 ) . \\n such evolution is not driven entirely by the presence of the cool cores . \\n this result has been recently confirmed by maughan et al . \\n ( 2007 ) .    in this paper \\n , we present measurements of the radial temperature and metallicity profiles of a sample of 12 clusters with temperatures larger than 6 kev observed with chandra at intermediate redshift , @xmath23 . \\n we take advantage of the acis superior spatial and spectral resolution to investigate in a systematic fashion the differences that may exist between cc and ncc clusters . \\n the spectroscopic measurements of the icm temperature and metallicity allow to characterize statistically the radial profiles and to quantify their gradients in this unexplored redshift region . \\n all the uncertainties are quoted at 1@xmath24 ( 68% ) for one interesting parameter . \\n the abundance estimates are relative to the compilation of cosmic values given in anders & grevesse ( 1989 ) ( hereafter ag89 ) , unless otherwise stated . \\n indeed , these values for the solar metallicities have more recently been superseeded by the new values by grevesse & sauval ( 1998 ) and asplund et al . \\n ( 2005 ) ( hereafter a05 ) , who introduced a 0.676 and 0.60 times lower iron solar abundance , respectively ( photospheric value ) , while the other elements do not change significantly . \\n our measures of metallicity are expected to be driven mainly by iron , however , for clarity , we also performed the fits using solar abundances by a05 . \\n + throughout this paper we assume @xmath25 km s@xmath26 mpc@xmath26 , @xmath27 , @xmath28 and @xmath29 . \\n from chandra archival data we select a sample of twelve intermediate redshift clusters ( @xmath23 ) . we also require the clusters to have at least @xmath0 acis - s or acis - i counts in order to study their properties in at least 3 circular annuli . \\n the sample is presented in table  [ sample ] , where the name of the cluster and the chandra observing logs are listed . \\n +    lccccccc a2034 & 0.113 & acis - i & 2001 may 05 & 2204 & 53.9 & 53.9 & 1.6 + a1413 & 0.143 & acis - i & 2001 may 16 & 1661 & 9.7 & 9.7 & 2.2 + & & acis - i & 2004 mar 06 & 5003 & 76.1 & 75.0 & + & & acis - i & 2005 feb 03 & 5002 & 37.2 & 36.5 & + a907 & 0.153 & acis - i & 2000 jun 29 & 535 & 11.0 & 10.9 & 5.4 + & & acis - i & 2002 jun 14 & 3185 & 48.7 & 47.9 & + & & acis - i & 2002 oct 30 & 3205 & 47.7 & 40.5 & + a2104 & 0.155 & acis - s & 2000 may 25 & 895 & 49.8 & 48.9 & 8.7 + a1914 & 0.171 & acis - i & 2003 sep 03 & 3593 & 18.9 & 18.8 & 0.9 + a2218 & 0.176 & acis - i & 2001 aug 30 & 1666 & 49.2 & 20.2 & 3.2 + a963 & 0.206 & acis - s & 2000 oct 11 & 903 & 36.8 & 35.8 & 1.4 + a2261 & 0.224 & acis - i & 2004 jan 14 & 5007 & 24.6 & 24.3 & 3.3 + a2390 & 0.228 & acis - s & 2000 oct 08 & 500 & 9.8 & 9.8 & 6.8 + & & acis - s & 2003 sep 11 & 4193 & 96.3 & 91.0 & + a1835 & 0.253 & acis - s & 2000 apr 29 & 496 & 10.8 & 10.3 & 2.3 + zwcl3146 & 0.291 & acis - i & 2000 may 10 & 909 & 46.6 & 45.6 & 3.0 + a1995 & 0.319 & acis - s & 2000 may 08 & 906 & 57.5 & 53.8 & 1.4 +    the chandra data analysis has been performed using the latest version of ciao ( v3.3.0.1 ) . \\n all of our datasets are processed by a version of the standard data processing ( sdp ) pipeline prior to version ds 7.4.0 , which uses the tool @xmath30 to flag possible cosmic ray events in the level 1 event file ; it has been determined that a significant fraction of the x - ray events from a source in imaging mode might be removed using this tool . \\n therefore we reset the correction performed by @xmath30 on the level=1 event file , so that the hot pixels and the afterglow events may be properly removed by the improved ciao tool @xmath31 , ( introduced after sdp version ds 7.4.0 ) . \\n a new level=1 event file is then created ( through the ciao tool @xmath32 ) to apply the latest calibration files to the data ( e.g. apply the newest acis gain maps , apply the time - dependent acis gain correction , apply the acis charge transfer inefficiency correction , etc . ) . \\n moreover in the case of observations telemetered in vfaint mode it is possible to reduce the background using the additional screening of the events with significantly positive pixels at the border of the @xmath33 event island . \\n two further filtering steps are then required to obtain the level=2 event files , i.e. filter for bad grades ( using asca grades ) and for a `` clean '' status column and apply the good time intervals ( gtis ) supplied by the pipeline . \\n the final step is to examine background light curves during each observation to detect and remove the periods of high background , due to flaring episodes . \\n we perform the flare detection and removal following the recommendations suggested in markevitch et al . \\n ( 2003 ) ; both the total and the clean exposure times are listed in table  [ sample ] . \\n most of the observations are slightly affected by background flares thus we were able to use practically all the exposure time . \\n the only exceptions are obsid 3205 , 4193 , 906 and especially obsid 1666 , where @xmath34 ks of the exposure were lost due to high background . \\n +      an accurate subtraction of the background is crucial to perform a correct study of the spectral properties of the clusters in our sample , especially in their outskirts . \\n since we are dealing with extended objects , occupying most of the acis field of view we need to use a compilation of the blank - field observations , processed identically to the cluster observation ( i.e. as described above ) and reprojected onto the sky using the aspect information from the cluster pointing . \\n it is worth noticing that the synthetic backgrounds correspond to longer exposure times ( @xmath35 msec ) than any of our observations , giving us a very good sampling in the estimate of the background to subtract . \\n moreover , in order to tailor the background to our data we follow the recommendations given in the ciao web - pages . in particular we renormalize the blank - fields to the background in each observation , considering a region of the acis field of view practically free from cluster emission ( mainly acis - s1 for acis - s observations , and acis - s2 for acis - i observations ) and a spectral band ( 9.5 - 12 kev ) where the chandra effective area is nearly zero , therefore all the observed flux is due to the particle background . \\n in addition to the particle - induced background we check also if the diffuse soft x - ray background could be an important factor in our observations and if appropriate adjustments are needed . for each observation , we follow the procedure of vikhlinin et al . \\n ( 2005 ) , extracting a spectra in the source - free regions of the detector , subtracting the renormalized blank - field background and fitting the residuals in xspec v11.3.2p ( in the 0.4 - 1 kev band ) with an unabsorbed mekal model , whose normalization was allowed to be negative . \\n the best - fit model obtained is therefore included as an additional component in the spectral fits ( with its normalization scaled by the area ) . \\n however , in every observation the adjustments required are minimal and do not affect significantly the determination of @xmath36 and @xmath13 , even at large radii . \\n this is also due to the properties of the clusters in our sample , whose high @xmath36 values ( @xmath37 kev ) even in the resolved outer regions are not affected significantly from the method applied for the subtraction of the diffuse soft background . \\n the @xmath38 statistics require grouping of the spectra , having at least 20 counts per bin , in order to be able to approximate the poissonian distribution of counts with a gaussian . on the contrary , cash statistics do not require any grouping and represent a more reliable ( and less biased ) approach to fit the data . \\n indeed , it is well known from the literature ( see e.g. nousek & shue 1989 ; balestra et al . \\n 2007 ) that the @xmath38 statistics systematically `` sees '' the observed spectra softer than the real ones . \\n this usually leads to an overestimate of the slope of the observed spectra in the case of a simple power - law fit , while in the case that a thermal model is fitted to the data , the temperature measured is usually underestimated . as a test to see whether this systematics is present also in our data , we have decided to apply both these fit statistics . \\n we find that for all the clusters of the sample , a systematically lower temperature is measured with the @xmath38 ( on average @xmath39 lower , depending on the cluster ) . on the other hand \\n no obvious systematic trend is observed in the determination of @xmath13 , being the variation in the best  fitting value of the metallicity in each cluster ranging between @xmath40 and @xmath41 with no preferential direction . to avoid the dependence on the grouping method , and the bias in the best - fit temperature , we decide to use the modified cash statistics , as implemented in xspec v11.3.2p , to determine the best - fit parameters and their uncertainties .      in order to study the radial properties of the cluster emission \\n , we subdivide each cluster in annuli ( circular or elliptical , depending on the morphology of the cluster ) centered on the x - ray emission peak . in the more disturbed clusters , where an emission peak is not clearly identifiable , we assume the center of the cluster to correspond with the x - ray centroid at @xmath42 . \\n we require each region to have at least @xmath43 net counts , so that it would be possible to estimate the temperature and the metallicity of the annulus with sufficient accuracy . for each cluster \\n the outermost annulus corresponds to an area where the intensity of the source in the 0.8 - 8 kev band is roughly equal to that of the background . \\n we extract a spectra from each annulus after excluding the 3@xmath24 point sources detected by the ciao tool @xmath44 . \\n the source list produced is also inspected by - eye in order to remove possible additional sources not detected by @xmath44 ( especially in the regions where the diffuse emission from the cluster is brighter ) . \\n the ciao script used to perform the spectral extraction is @xmath45 , which generates source and background spectra and build the appropriate rmfs and arfs . \\n the background is taken from the re - normalized blank field observations using the same region of the source . + \\n the spectra are analyzed with xspec v11.3.2p ( arnaud et al . 1996 ) and fitted by a single - temperature mekal model ( kaastra 1992 ; liedahl et al . \\n 1995 ) in which the ratio between the elements is fixed to the solar value as in ag89 . \\n however , as explained in  1 , these values for the solar metallicities have more recently been superseeded by the new values by grevesse & sauval ( 1998 ) and a05 . for clarity and completeness \\n , we also performed the fits using solar abundances by a05 . \\n the free parameters in the model are the temperature @xmath36 , the metallicity @xmath13 of the gas and the normalization . \\n the spectral band considered in the fit is the 0.6 - 8 kev . \\n we choose not to consider the data below 0.6 kev because of uncertainties in the acis calibration below that energy . \\n the @xmath46 derived from the x - rays is found to be consistent ( within 1@xmath24 ) with the galactic value in the line of sight of each observation , as derived from radio data ( stark et al . \\n 1992 ) , except in the cases of a2104 and a2390 ( see table  [ sample ] and following   [ text2104 ] ) . in these clusters \\n the @xmath46 value measured from x - ray data is significantly different ( at more than 2@xmath24 confidence level ) from the radio value , therefore we adopt the x - ray value . \\n the @xmath46 value is fixed to the galactic value obtained from the radio data ( and listed in table  [ sample ] ) in the rest of the sample . \\n we have measured @xmath46 from the x - ray data in each annulus , finding no evidence of radial variation . \\n therefore , @xmath46 is fixed to the same value in all the radial annuli . \\n we have divided then our sample in cooling - core and non - cooling - core clusters according to their central cooling time . \\n the gas temperature and density profiles are recovered from the single - phase spectral fit done in annular rings by correcting the emissivity in each shell by the contrubution of the outer shells moving inwards . \\n a detailed description of the procedure is presented in ettori et al . \\n ( 2002 ) . in brief , \\n the normalization of the thermal component , being proportional to the emission integral , provides the gas density , whereas the deprojected temperature is provided by weighting for the corrected emissivity the spectral measurement . \\n the deprojected values in the innermost bin are then used to estimate the central cooling times @xmath47 , where @xmath48 and @xmath49 are appropriate for a plasma with a metallicity of 0.3 times the solar values in ag89 , @xmath50 , @xmath51 and @xmath52 are the gas temperature , electron density and emissivity in the innermost bin , respectively . \\n +    lccccccc a2034 & 78,900 & @xmath53 & @xmath54 & 2,222 & 76 - 433 & @xmath55 & @xmath56 + a1413 & 181,500 & @xmath57 & @xmath58 & 2,416 & 67 - 385 & @xmath59 & @xmath60 + a907 & 87,500 & @xmath61 & @xmath62 & 2,125 & 56 - 320 & @xmath63 & @xmath64 + a2104 & 63,100 & @xmath65 & @xmath66 & 2,290 & 60 - 341 & @xmath67 & @xmath68 + a1914 & 39,100 & @xmath69 & @xmath70 & 2,672 & 64 - 367 & @xmath71 & @xmath72 + a2218 & 18,300 & @xmath73 & @xmath74 & 2,202 & 52 - 295 & @xmath75 & @xmath76 + a963 & 41,800 & @xmath77 & @xmath78 & 2,161 & 45 - 256 & @xmath79 & @xmath80 + a2261 & 21,500 & @xmath81 & @xmath82 & 2,400 & 47 - 267 & @xmath83 & @xmath84 + a2390 & 202,600 & @xmath85 & @xmath86 & 2,693 & 52 - 295 & @xmath87 & @xmath88 + a1835 & 23,100 & @xmath89 & @xmath90 & 2,500 & 44 - 254 & @xmath91 & @xmath92 + zwcl3146 & 40,500 & @xmath93 & @xmath94 & 2,582 & 41 - 237 & @xmath95 & @xmath96 + a1995 & 30,200 & @xmath97 & @xmath98 & 2,427 & 37 - 209 & @xmath99 & @xmath100 +    the central cooling times are reported in table  [ xrayprop ] , as well as the age @xmath101 of each cluster , and the ratio between the two quantities . \\n the age of the universe at the @xmath102 of observation is used as an upper limit to the age of the cluster . \\n bauer et al . \\n ( 2005 ) computed the cooling times for 6 of the clusters in our sample ( a1835 , a1914 , a2218 , a2261 , a2390 and zwcl3146 ) finding a @xmath103 in the center of the cluster , or at 50  kpc , consistent with the values computed for the central bin in our spectral analysis ( which might extend farther out than 50  kpc from the center in some cases ) . following their criterium , \\n a clear separation between the cc and the ncc in our sample can be located at @xmath104 gyr ( figure  [ histotc ] ; corresponding to @xmath105 ) . \\n we have 4 clusters presenting signs of strong cooling ( @xmath106 gyr ) and 3 clusters exhibiting signs of mild cooling ( @xmath107 gyr ) . \\n the remaining 5 clusters can be classified as ncc , presenting longer cooling times in the center .    the projected temperature and \\n metal abundance profiles for both cc and ncc objects are shown in figures  [ temperatures ] and  [ abundances ] .      * a2034 * : a2034 ( z=0.113 ) has been observed with chandra in one acis - i pointing ( obsid : 2204 ) . \\n the temperature profile we derived is quite flat in the central regions of the cluster , where the temperature is @xmath108 kev . \\n it shows however a negative gradient after 400 kpc from the center . \\n a similar trend is observed in the metallicity , where the average value of @xmath109 within 400 kpc from the center decreases to @xmath110 at larger radii . \\n * a1413 * : a1413 ( z=0.143 ) has been observed four times with acis - i . \\n we discard one observation ( obsid : 537 ) which is affected almost entirely by a persisting flare . in one of the observations used in our analysis ( obsid : 5003 ) \\n the source is placed in a position of the acis - i array very close to the s2 chip , therefore s2 is still contaminated by source emission and we can not use it to re - normalize the blank field to the background in the observation . \\n we use instead part of the i1 chip ( which is front - illuminated as s2 ) to re - normalize , since it is more distant from the cluster center than s2 and therefore less contaminated by cluster emission . \\n the resulting temperature profile shows a slight decrease in temperature towards the center ( @xmath111 kev within the inner 150 kpc ) . \\n a1413 has been also observed by xmm - newton ( pratt & arnaud 2002 ) , representing one of the clusters with the most accurate temperature profile observed by this satellite . \\n this cluster is also part of the sample of chandra clusters analyzied by vikhlinin et al . \\n the xmm - newton observation does not find any evidence of a cool core , in contrast with the temperature profiles obtained with chandra both in our analysis and even more evidently in vikhlinin et al . \\n . this might be due to the poorer angular resolution of xmm - newton with respect to chandra . \\n + the metallicity profile is decreasing towards larger radii , and consistent within 1@xmath24 with the measures of vikhlinin et al . \\n ( 2005 ) . \\n * a907 * : a907(z=0.153 ) has been observed with chandra in three separate acis - i pointings ( obsid : 535 , 3185 and 3205 ) , all of them used in our analysis . \\n the temperature profile shows an evidence of a cool core in the center of the cluster ( @xmath112 kev in the central 100 kpc ) . \\n the metallicity profile presents a decreasing trend toward larger radii . \\n a907 is also part of the cluster sample analyzed by vikhlinin et al . \\n their results , both for the temperature and the metallicity , are fully consistent with ours within the 1@xmath24 statistical uncertainties . \\n * a2104*:[text2104 ] a2104 ( z=0.155 ) has been observed with chandra in one acis - s pointing ( obsid : 895 ) . as described in \\n [ specanal ] , the value of the @xmath46 measured from the x - ray data alone is significantly different from the radio value , thus we have decided to fix the @xmath46 to the best fit value obtained from the fit ( @xmath113 @xmath114 ) . the cluster does not show any evidence of a cool core in its center , having a temperature profile decreasing towards the outskirts . \\n the metallicity profile is consistent with being flat , with a value @xmath115 , within the 1@xmath24 uncertainties .    * a1914 * : two acis - i pointings of a1914 ( z=0.171 ) are available in chandra archive . \\n however the oldest ( and shortest ) observation ( obsid : 542 ) has been performed in 1999 . for observations performed in that year an accurate modeling of the acis background is not currently available . \\n thus to avoid problems in background subtraction we have decided to discard it and keep only the longest observation ( obsid : 3593 ) . \\n a negative gradient in @xmath36 is quite clear : the temperature drops from @xmath116 kev in the center down to @xmath117 kev in the outer radial bin . \\n a similar trend is observed also in the abundance profile , where @xmath118 in the center , then decreasing to @xmath119 in the two outer radial bins . \\n this is one of the few examples of metallicity peak without a corresponding cool core ( or temperature drop ) towards the center .    * \\n a2218 * : a2218 ( z=0.176 ) has been observed three times with acis - s . \\n unfortunately two of these observations ( obsid : 553 and 1454 ) were performed in 1999 and for the reason described in the case of a1914 we have decided to discard them . \\n moreover the remaining observation ( obsid : 1666 ) has been strongly affected by a flare which reduces the good exposure time to only @xmath120 ks . with these data we are able to observe the presence of a centrally peaked temperature profile ( a hot , instead of a cool core ) and a costant metallicity profile . \\n a temperature profile peaked toward the center has been also seen by machacek et al . \\n ( 2002 ) , analyzing the two chandra observations performed in 1999 . \\n this is consistent with the picture of a2218 being involved in a line - of - sight merger , as suggested by a considerable disturbance of the intracluster gas in the x - rays and by the observed substructure in the optical ( e.g. pratt et al . \\n 2005 ) . \\n * a963 * : a963 ( z=0.206 ) has been observed with chandra in one acis - s pointing ( obsid : 903 ) . \\n we found a decreasing trend of @xmath13 with the radius , with only a very weak hint for the presence of a lower temperature in the center .    * a2261 * : two pointings of a2261 ( z=0.224 ) are available in the chandra archive . \\n one of the observations ( obsid : 550 ) has been performed in 1999 and therefore we discard it for the reason described above in the case of a1914 . \\n the temperature profile does show only a hint ( more than 2@xmath24 however ) of a decrease in the center , where the temperature drops down from @xmath121 kev to @xmath122 kev . \\n the metallicity profile shows a constant behaviour for the first two bins and a decrease ( significant at more than 1@xmath24 ) in the outer radial bin .    * a2390 * : a2390 ( z=0.228 ) has been observed three times with acis - s . \\n one of the observations ( obsid : 501 ) has been performed in 1999 and therefore we discard it . \\n we concentrate our analysis on the remaining two observations ( obsid : 500 and 4193 ) , yielding a total of @xmath123 ks of good observing time . \\n the value of the @xmath46 derived from the x - rays ( @xmath124 @xmath114 ) is significantly different than the radio value , therefore we adopted the x - ray value in the spectral fits . \\n a2390 is also part of the sample analyzed in vikhlinin et al . \\n similarly to them we find a cool core ( @xmath125 kev ) in the center of the cluster with a @xmath36 profile getting flatter going towards the outskirts , being fully consistent with their measured temperatures at every radius . on the other hand , \\n the metallicity profile shows just a hint of a peak in the central part of the cluster . \\n it is however consistent at 1@xmath24 with the profile of vikhlinin et al . \\n ( 2005 ) and not sensitive to the choice of the @xmath46 .    * a1835 * : two different acis - s observations of a1835 ( z=0.253 ) are present in the chandra archive . \\n we discard the older ( and longer ) observation ( obsid : 495 ) , performed in 1999 because of the reason described in the case of a1914 , keeping only the @xmath126 ks observation performed in 2000 ( obsid : 496 ) \\n . the temperature profile of a1835 shows a clear evidence of a cool core in its center where @xmath36 drops down by a factor of @xmath127 . \\n moreover the temperature shows a decline after 300 kpc , going toward larger radii . \\n piffaretti et al . \\n ( 2005 ) analysed xmm - newton observations of a1835 and detected a temperature decrease at large radii , as in our data . \\n majerowicz et al . \\n ( 2002 ) also analysed xmm - newton data and found a decrease in the temperature profile at large radii ( at @xmath128 kpc from the center ) ; however their temperature profile becomes constant after such decrease . \\n the decrease at large radii has not been observed in the analysis of chandra data by voigt & fabian ( 2006),who found a constant temperature outside the central 100 kpc . \\n however it is worth noticing that in their work they analysed the 1999 observation ( instead of the 2000 observation , as in our analysis ) which might have background subtraction problems especially at large radii . \\n this may explain the difference between the two profiles . \\n the metallicity profile shows a decreasing gradient in the first two bins , becoming constant afterwards . \\n the only comparison with the literature comes from an xmm - newton observation analyzed by majerowicz et al . \\n ( 2002 ) , where an almost constant metallicity profile at every radius has been observed .    * zwcl3146 * : \\n zwcl3146 ( z=0.291 ) has been observed with acis - i in one pointing ( obsid : 909 ) . \\n also this cluster clearly shows the presence of a cool core ( @xmath36 dropping down by a factor of almost 2 ) . a decreasing trend in metallicity from @xmath129 in the center , down to @xmath130 in the outer bin , is also observed .    * a1995 * : one acis - s observation of a1995 , the farthest cluster in our sample ( z=0.319 ) , is present in the chandra archive ( obsid : 906 ) . \\n although this observation is quite long ( @xmath131 ks of good exposure time ) the number of counts available allowed us to divide this cluster only in three radial bins . \\n the temperature profile of a1995 is consistent to be flat within the errors with a temperature around 9 kev . \\n the abundance profile seems to have a positive gradient in the outer bin , however the errors are large and this increase in @xmath13 is not very significant . \\n one of the main goals of this paper is to look for a ( purely phenomenological ) self - similarity in the radial profiles of temperature and metallicity , after they are scaled to the cluster virial radius @xmath132 . \\n a measure of @xmath132 is thus crucial to test for such self - similarity in our cluster sample . \\n this quantity can be approximated by the following relation : @xmath133 as calibrated from the non - radiative hydrodynamical simulations of clusters by evrard et al . \\n it is worth noticing that this relation is in agreement with the scaling relations observed ( e.g. ettori et al . 2004 ) in the x - rays , where the dependency on @xmath36 is consistent with eq.(1 ) and only the absolute normalization may experience some variations . to compute the global temperature @xmath134 necessary to estimate @xmath132 we extract spectra including emission going from 0.07@xmath132 to 0.4@xmath132 in each cluster . \\n the central regions of each cluster are therefore excluded from the spectra in order to avoid contamination from a possible cool core . \\n the values of @xmath134 and @xmath132 have been evaluated iteratively until a convergence to a stable value of the temperature is obtained ( @xmath135 kev between two different iterations ) . from the fits we are able to determine also a global metallicity @xmath136 in each cluster . in table \\n [ xrayprop ] we list the best - fit values for @xmath134 and @xmath136 , and the value of @xmath132 computed using the formula above . \\n the minimum and maximum apertures used to extract the total spectrum are listed as well . \\n +      figure  [ temperatures ] shows the normalized temperature profiles for all the cc clusters ( panel b ) compared with the ncc clusters ( panel d ) . \\n this figure has been obtained by normalizing the temperatures in each cluster to its average temperature @xmath134 computed from the total cluster spectrum excluding the central @xmath137 . \\n the error - weighted mean and the best - fit results after fitting with single power - laws @xmath138 are presented in table  [ bestfit ] .    within @xmath2 , \\n the temperature profiles in cc objects increases with a slope @xmath139 . moving outwards , between @xmath2 and the outer radial limit of our spectral analysis at @xmath140 , these profiles behave as @xmath141 . \\n non - cooling - cores systems have , on average , a profile that is almost flat at @xmath142 and then decreases rapidly as @xmath143 . in the outskirts , \\n the temperature profiles of cc and ncc clusters show a significant discrepancy between their slopes , being ncc more deviant from the isothermal case . \\n our best fit functional for the cc sample is fully consistent with the best fit functional form found by vikhlinin et al . \\n ( 2005 ) in their sample of cc clusters , at @xmath144 . \\n the two functionals diverge significantly only above @xmath145 , where our profile is flatter ( and therefore the value of @xmath146 is higher ) than vikhlinin et al . \\n ( 2005 ) profile . \\n however , only a few of our data points are located beyond that radius , preventing us from any statistically significant comparison between the two samples at @xmath147 . \\n lccc & all @xmath148 & @xmath149 & @xmath150 + all & @xmath151 & @xmath152 & @xmath153 + & @xmath154 & @xmath155 & @xmath156 + & @xmath157 & @xmath158 & @xmath159 + & @xmath38/dof=@xmath160 & @xmath38/dof=@xmath161 & @xmath38/dof=@xmath162 + & & & + cc & @xmath163 & @xmath164 & @xmath165 + & @xmath154 & @xmath166 & @xmath167 + & @xmath168 & @xmath169 & @xmath170 + & @xmath38/dof=@xmath171 & @xmath38/dof=@xmath172 & @xmath38/dof=@xmath173 + & & & + ncc & @xmath174 & @xmath175 & @xmath176 + & @xmath177 & @xmath178 & @xmath179 + & @xmath180 & @xmath181 & @xmath182 + & @xmath38/dof=@xmath183 & @xmath38/dof=@xmath184 & @xmath38/dof=@xmath185 + & & & + & & @xmath186 & + & all @xmath148 & @xmath149 & @xmath150 + all & @xmath187 & @xmath188 & @xmath189 + & @xmath190 & @xmath191 & @xmath192 + & @xmath193 & @xmath194 & @xmath195 + & @xmath38/dof=@xmath196 & @xmath38/dof=@xmath197 & @xmath38/dof=@xmath198 + & & & + cc & @xmath199 & @xmath200 & @xmath201 + & @xmath202 & @xmath203 & @xmath204 + & @xmath205 & @xmath206 & @xmath207 + & @xmath38/dof=@xmath208 & @xmath38/dof=@xmath209 & @xmath38/dof=@xmath210 + & & & + ncc & @xmath211 & @xmath212 & @xmath213 + & @xmath214 & @xmath215 & @xmath216 + & @xmath217 & @xmath218 & @xmath219 + & @xmath38/dof=@xmath220 & @xmath38/dof=@xmath221 & @xmath38/dof=@xmath222 +    adopting the a05 abundances has not changed the best - fit values of @xmath36 at every radius ( always fully consistent within the 1@xmath24 errors ) in the individual clusters , therefore the best fit functionals representing both the cc and the ncc sample have not varied . \\n a clearer picture can be seen also if we compute an error - weighted average of the @xmath36 profiles in several bins of width 0.05 in @xmath223 . \\n the contribution to the single bin is provided from the measurements ( and relative error ) that fall into that bin , weighted in proportion to the percentage of the spatial coverage of the bin . \\n the error - weighted mean @xmath146 profile is plotted in figure  [ t_cc_vs_nocc_mean ] and compared with the local estimates from dm02 . \\n cc and ncc objects show well defined opposite gradient in the inner radial and more similar behaviour moving outwards . \\n a good agreement is also observed with the local profiles , apart from two significant deviations : ( i ) our cc mean profile appears flatter at @xmath224 , with an error - weighted value of @xmath225 ( r.m.s . \\n 0.07 ) , to be compared with the local value of @xmath226 ( r.m.s . \\n 0.16 ) , ( ii ) our ncc profile is steeper within @xmath2 , with a mean value of @xmath227 ( r.m.s . \\n 0.14 ) with respect to the local value of @xmath228 ( r.m.s . \\n 0.07 ) . \\n the metallicity profiles are plotted against the radius normalized to @xmath132 for the cc and ncc sample in figure  [ abundances]b and [ abundances]d , respectively . \\n a different behaviour in the very central regions between the two samples is quite clear . to characterize this behaviour , \\n we have fitted the normalized profiles @xmath186 with respect to @xmath223 with single power - laws @xmath138 over different radial ranges . while the ncc clusters presents a flat profile within @xmath229 , a sharper negative gradient \\n is observed in the cc cluster sample ( @xmath230 ; see table  [ bestfit ] ) . also at @xmath150 , \\n where a model with a single power - law well reproduce the data ( reduced @xmath38 less than 1 ) , the cc clusters show hints of a steeper profile ( @xmath231 in the cc sample , @xmath232 in the ncc sample ) . \\n we compute an error - weighted average @xmath13 profile as done for the temperature profile and compare it with the local measurements in dm01 , after scaling the radii to @xmath132 ( see figure  [ z_cc_vs_nocc_mean ] ) . \\n the two profiles are in agreement at @xmath233 , with both subsamples showing an evidence for a negative gradient in metallicity significant at least at 2@xmath24 . \\n a different behaviour between the two subsample is observable in the central bin , where the value in the cc sample is @xmath234 higher than in the ncc sample . \\n it is worth noticing that all the clusters in our sample have @xmath1 kev and this trend may be different in lower temperature clusters . \\n dm01 in their analysis observed a clear gradient in the metallicity profiles of their cc clusters , while the profiles of their ncc clusters were almost constant . \\n moreover the average metallicity observed in the cc clusters was systematically higher than in the ncc sample , at least within @xmath235 from the center . in our analysis , we do not find a clear difference between the cc and ncc abundance profiles as in dm01 . \\n except for the inner radial bin where the metallicity in cc objects can be higher by 50 per cent than in ncc ones , the cc and ncc profiles are very similar and consistent within the errors . \\n to compare our mean values at intermediate redshift with the results obtained locally from dm01 , we estimate an error - weighted average @xmath13 profile for both cc and ncc objects in local and intermediate @xmath102 samples ( figure  [ z_cc_vs_nocc_mean ] ) . while the slope of the profiles is generally in agreement with dm01 for the both the cc and ncc clusters , the value of @xmath186 is systematically higher in our sample with respect to the dm01 sample , with differences up to 50% within @xmath2 of cc systems . \\n this might be due to the different method used to compute @xmath136 , being in dm01 work estimated as fit with a constant to the radial metallicity profile . however , apart from the inner radial region , the discrepancy between the local profiles and the ones at intermediate redshits are within 1@xmath24 . using the same method to determine @xmath136 on our data , we find that the values of @xmath186 are fully consistent with dm01 .      all the analysis described in the current section \\n has been performed adopting the ag89 compilation of photospheric abundances . \\n this choice has been due mainly by the necessity to have a direct comparison with previous works in the literature ( e.g. dm01 ) . \\n however , as explained above in  1 , the abundance values listed in ag89 have been recently superseeded by the new photospheric values by grevesse & sauval ( 1998 ) and a05 , who introduced a 0.676 and 0.60 times lower iron solar abundance , respectively . \\n therefore , we have also performed the fits using solar abundances by a05 to check whether adopting the `` old '' ag89 values might have introduced any bias in our analysis . \\n + the shape of the @xmath13 profile for both the cc sample and the ncc sample resembles very closely that observed in figure  [ z_cc_vs_nocc_mean ] for the ag89 values of @xmath13 . however to better quantify this comparison we fitted also these new values with a power - law functional . \\n we measure @xmath236 with @xmath237 . \\n if we compare the result of the fit with the last two rows in the first column in table  [ bestfit ] , it is quite clear that the slope of the power - law in both the cc and ncc sample is consistent with what we obtained using the ag89 values ( well within the 1@xmath24 uncertainties ) and the difference is only in the normalization . as expected , this result might indicate that our metallicities are mostly driven by iron and that the contribution of the @xmath10 elements to the determination of the abundances is negligible . \\n indeed , all our clusters have a temperature larger than @xmath238 kev , therefore the abundance measures are dominated by the fe - k@xmath10 line . as a further test to this hypothesis we tried to fit the fe abundance independently from the @xmath10 elements abundances . \\n to this aim we used a vmekal model where the abundances of o , mg , si and s were tied - up to the same value and fitted as a single free parameter ( in order to reduce the number of free parameters ) , while the other elements ( apart from fe ) were frozen at solar . while the fe abundance remained always consistent with the value of @xmath13 measured considering the metallicity as a single parameter , in almost all the spectra we could not find any statistically significant detection of a contribution from @xmath10 elements . \\n their abundances has been measured as upper limits in most cases ( generally @xmath239 ) , and as very low values in the rest of the spectra ( generally @xmath240 , often consistent with @xmath241 at 1@xmath24 ) . \\n this is true even in the inner part of the clusters in the sample , where the signal - to - noise of the spectra is higher and in principle it may be easier to detect the presence of elements other than iron . \\n + these results suggest that the measure of @xmath13 in our cluster sample consists mainly in a measure of iron metallicity . \\n therefore , adopting the ag89 solar abundances instead of the a05 ( which have different @xmath242 ratios ) produces only a difference in the value of the relative @xmath13 measured . \\n this does not introduce any bias in the analysis of the radial profiles , since the absolute value of @xmath13 does not change and only the reference value assumed for the solar metallicity experience a variation . \\n we investigate the correlation of the central slopes of the temperature and metallicity profiles with the central cooling time in each cluster . \\n to this aim , the values of @xmath243 , @xmath244 and @xmath223 ( normalized to the average temperature , the average metallicity and the virial radius measured in each cluster , respectively , as described in section  3 ) with @xmath142 have been considered to characterize the cooling cores . \\n we find that the most robust correlation is present between the slope @xmath245 of the temperature profiles , @xmath246 and @xmath247 , with a spearman s @xmath248 rank correlation value of -0.87 that corresponds to a significance of the non - correlation case of @xmath249 . in the @xmath250 and @xmath251 relations , the values of the spearman s @xmath248 are 0.44 and 0.54 , corresponding to a significance of 0.15 and 0.07 , respectively . \\n the exponent @xmath245 correlates with @xmath247 , being higher at lower values of @xmath247 , with all the cc clusters having @xmath252 and @xmath6 ( figure  [ alphatc ] ) . \\n in the present work we analyzed a sample of 12 galaxy clusters present in the chandra archive with at least @xmath0 net acis counts and @xmath1 kev . \\n these clusters were chosen in the 0.1 - 0.3 redshift range , regardless of their shape . \\n we computed the cooling time of the clusters , subdividing the sample in 7 cool core clusters and 5 non  cool core clusters . \\n this subdivision allowed us to compare the two categories in a systematic fashion , following the approach of dm01 . \\n we performed a spectral analysis in radial bins of each cluster in the sample requiring each bin to have @xmath253 counts , fitting the spectra with a thermal model with galactic absorption . \\n this allowed us to derive temperature and metallicity profiles for each cluster . \\n the virial radius @xmath132 was computed in order to renormalize the radii to physically meaningful quantities and investigate for self - similarities in the radial profiles . to this \\n aim the global temperature @xmath134 and metallicity @xmath136 in each cluster were measured as well . \\n the main results coming from our work can be summarized as follows . \\n +    * the temperature profiles in the inner @xmath2 have , on average , a positive gradient , @xmath254 with @xmath255 in cc systems , whereas it is almost flat in ncc systems . \\n the outer regions are well fitted with a single power - law with slopes significantly different , being steeper ( @xmath256 ) in ncc objects . \\n the general trend of our cc sample is fully consistent with vikhlinin et al . \\n ( 2005 ) at @xmath144 . \\n the low number statistics above @xmath145 prevents us from any statistically significant comparison between the two samples at @xmath147 . * \\n the metallicity profiles in the inner regions is almost constant in ncc clusters around the value measured excluding counts from @xmath257 . in the cc sample , \\n a steep negative gradient is observed ( @xmath258 ) in the central regions . at @xmath150 , \\n a power - law reproduces well the distribution of the spectral measurements , with a slope that is marginally steeper in cc clusters ( @xmath259 ) than in ncc clusters ( @xmath260 ) . * \\n comparing our averaged metallicity profiles with the ones in dm01 , we found that our values of @xmath186 are systematically higher , with differences up to 50% within @xmath2 of cc systems . \\n this may be explained by the different method adopted in dm01 to estimate @xmath136 , as best - fit with a constant over the entire metallicity profile , without any exclusion of the central core . * \\n using the solar abundances from asplund ( 2005 , a05 ) gives consistent results with what we obtain using the values by anders & grevesse ( 1989 , ag89 ) , with a discrepancy only in the normalization ( as expected , @xmath261 higher ) but not in the slope of the @xmath13 radial profiles . \\n together with the fact that , in most cases , we were able to measure the @xmath10 elements only as upper limits , this indicates that our metallicities are mostly driven by iron and that adopting the ag89 solar abundances instead of the a05 results in a difference only in the absolute values of the @xmath13 measured but does not introduce any bias in the radial profile analysis . * fitting a power  law shape to the temperature profiles , @xmath262 , we found that @xmath245 correlates strongly with the cluster cooling times , being higher at low values of @xmath247 , with all the cc clusters having @xmath263 and @xmath6 . \\n as expected , strong correlation is also observed between the inner slope of the metallicity profile and cluster cooling time . \\n in general , our results further demonstrate the invaluable role played by x \\n ray archival studies of the chemo and thermo  dynamical properties of galaxy clusters . \\n analyses based on the chandra archive , like that presented here ( see also vikhlinin et al . \\n 2005 ; balestra et al . 2007 ; maughan et al . \\n 2007 ) , in combination with analogous studies from the xmm  newton archive , will constitute an important heritage from the present generation of x  ray satellites for years to come . \\n nowadays , available data on the evolution of the chemical enrichment of the icm provide important constraints on models aimed at explaining the past history of star formation and the dynamical processes taking place during the cosmological build up of galaxy clusters . \\n however the study of the thermo - dynamical properties of the cooling cores and the evolution of the abundance distributions in clusters with the redshift are just a part of what can be currently done exploiting in full the existing chandra and xmm  newton archives . \\n archival works like ours have the potential to shed new light on the properties of the stellar populations responsible for the icm enrichment , and on the mechanisms which lead to the generation of the cool cores and determine the transport and diffusion of heavy elements from star forming regions . \\n ab and pm acknowledge financial support from cxo grant ar6 - 7015x and from nasa grant go5 - 6124x . \\n we acknowledge financial contribution from contract asi  inaf i/023/05/0 . \\n pt and sb acknowledge financial contribution from the pd51 infn grant . \\n we thank a. vikhlinin for providing us the temperature and abundance profiles of some of the clusters in his sample . \\n we also thank f.gastaldello for useful discussions . \\n we thank the anonymous referee for comments and suggestions useful to improve the presentation of the paper .\",\n",
       " 'abstract': 'we present the analysis of the temperature and metallicity profiles of 12 galaxy clusters in the redshift range 0.10.3 selected from the chandra archive with at least @xmath0 net acis counts and @xmath1 kev . \\n we divide the sample between 7 cooling - core ( cc ) and 5 non - cooling - core ( ncc ) clusters according to their central cooling time . \\n we find that single power - laws can describe properly both the temperature and metallicity profiles at radii larger than @xmath2 in both cc and ncc systems , showing the ncc objects steeper profiles outwards . \\n a significant deviation is only present in the inner @xmath2 . \\n we perform a comparison of our sample with the de grandi & molendi bepposax sample of local cc and ncc clusters , finding a complete agreement in the cc cluster profile and a marginally higher value ( at @xmath3 ) in the inner regions of the ncc clusters . \\n the slope of the power - law describing @xmath4 within @xmath2 correlates strongly with the ratio between the cooling time and the age of the universe at the cluster redshift , being the slope @xmath5 and @xmath6 in cc systems .'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_summarization[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_preprocess_function(article_data):\n",
    "    inputs = [prefix + abstract for abstract in article_data[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=article_data[\"abstract\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44d9191653140c3827786eaf4b8d45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162429 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1 tokenized_arxiv_summarization = arxiv_summarization.map(summarize_preprocess_function, b     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataset_dict.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">851</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 848       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cache_file_names <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849          </span>cache_file_names = {k: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>}                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DatasetDict(                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 851 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>{                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 852             </span>k: dataset.map(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853                </span>function=function,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854                </span>with_indices=with_indices,                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataset_dict.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">852</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;dictcomp&gt;</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849          </span>cache_file_names = {k: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>}                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DatasetDict(                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 851          </span>{                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 852 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>k: dataset.map(                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853                </span>function=function,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854                </span>with_indices=with_indices,                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 855                </span>with_rank=with_rank,                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">563</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 560       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 561          </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span> = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"self\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 562       # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 563 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 564       </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 565       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 566          # Remove task templates if a column mapping of the template is no longer val</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">528</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 525          </span><span style=\"color: #808000; text-decoration-color: #808000\">\"output_all_columns\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._output_all_columns,                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526       </span>}                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527       # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 528 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529       </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530       # re-apply format to the output</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">300</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3001                </span>leave=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3002                </span>desc=desc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"Map\"</span>,                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3003             </span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> pbar:                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3004 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> rank, done, content <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> Dataset._map_single(**dataset_kwargs):     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3005                   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> done:                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006                      </span>shards_done += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3007                      </span>logger.debug(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Finished processing shard number {</span>rank<span style=\"color: #808000; text-decoration-color: #808000\">} of {</span>n  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">338</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_map_single</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3377                      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(*(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">slice</span>(i, i + batch_size).indices(shard.num_rows)))    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3378                   </span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Something simpler?</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3379                   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3380 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>batch = apply_function_on_filtered_inputs(                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3381                         </span>batch,                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3382                         </span>indices,                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3383                         </span>check_same_num_examples=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(shard.list_indexes()) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>,    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">326</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply_function_on_filtered_inputs</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3258             </span>additional_args += (effective_indices,)                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3259          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> with_rank:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3260             </span>additional_args += (rank,)                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3261 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3262          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(processed_inputs, LazyDict):                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3263             </span>processed_inputs = {                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3264                </span>k: v <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> processed_inputs.data.items() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> processed  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">summarize_preprocess_function</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">summarize_preprocess_function</span>(article_data):                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2    </span>inputs = [prefix + abstract <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> abstract <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> article_data[<span style=\"color: #808000; text-decoration-color: #808000\">\"article\"</span>]]                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>model_inputs = tokenizer(inputs, max_length=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1024</span>, truncation=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4    </span>labels = tokenizer(text_target=article_data[<span style=\"color: #808000; text-decoration-color: #808000\">\"abstract\"</span>], max_length=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">128</span>, truncation=     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5    </span>model_inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>] = labels[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>]                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_inputs                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2488</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2485          # input mode in this case.</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2486          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._in_target_context_manager:                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2487             </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._switch_to_input_mode()                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2488 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>encodings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_one(text=text, text_pair=text_pair, **all_kwargs)      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2489       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> text_target <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2490          </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._switch_to_target_mode()                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2491          </span>target_encodings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_one(text=text_target, text_pair=text_pair_targ  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2574</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_one</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2571                </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(text_pair)<span style=\"color: #808000; text-decoration-color: #808000\">}.\"</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2572             </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2573          </span>batch_text_or_text_pairs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(text, text_pair)) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> text_pair <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2574 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.batch_encode_plus(                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2575             </span>batch_text_or_text_pairs=batch_text_or_text_pairs,                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2576             </span>add_special_tokens=add_special_tokens,                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2577             </span>padding=padding,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2765</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">batch_encode_plus</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2762          </span>**kwargs,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2763       </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2764       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2765 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._batch_encode_plus(                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2766          </span>batch_text_or_text_pairs=batch_text_or_text_pairs,                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2767          </span>add_special_tokens=add_special_tokens,                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768          </span>padding_strategy=padding_strategy,                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls_fast.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">429</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_batch_encode_plus</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">426          </span>pad_to_multiple_of=pad_to_multiple_of,                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">427       </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428       </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>429 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>encodings = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tokenizer.encode_batch(                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">430          </span>batch_text_or_text_pairs,                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">431          </span>add_special_tokens=add_special_tokens,                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">432          </span>is_pretokenized=is_split_into_words,                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1 tokenized_arxiv_summarization = arxiv_summarization.map(summarize_preprocess_function, b     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33mdataset_dict.py\u001b[0m:\u001b[94m851\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mmap\u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m cache_file_names \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m         \u001b[0mcache_file_names = {k: \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m \u001b[96mself\u001b[0m}                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m DatasetDict(                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 851 \u001b[2m         \u001b[0m{                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 852 \u001b[0m\u001b[2m            \u001b[0mk: dataset.map(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m               \u001b[0mfunction=function,                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m               \u001b[0mwith_indices=with_indices,                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33mdataset_dict.py\u001b[0m:\u001b[94m852\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<dictcomp>\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m         \u001b[0mcache_file_names = {k: \u001b[94mNone\u001b[0m \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m \u001b[96mself\u001b[0m}                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m DatasetDict(                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2m         \u001b[0m{                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 852 \u001b[2m            \u001b[0mk: dataset.map(                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m               \u001b[0mfunction=function,                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m               \u001b[0mwith_indices=with_indices,                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 855 \u001b[0m\u001b[2m               \u001b[0mwith_rank=with_rank,                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m563\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 560 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mself\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 562 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 563 \u001b[2m      \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 564 \u001b[0m\u001b[2m      \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 565 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 566 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# Remove task templates if a column mapping of the template is no longer val\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m528\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 525 \u001b[0m\u001b[2m         \u001b[0m\u001b[33m\"\u001b[0m\u001b[33moutput_all_columns\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m._output_all_columns,                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 526 \u001b[0m\u001b[2m      \u001b[0m}                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 528 \u001b[2m      \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m      \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# re-apply format to the output\u001b[0m                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m300\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m4\u001b[0m in \u001b[92mmap\u001b[0m                                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3001 \u001b[0m\u001b[2m               \u001b[0mleave=\u001b[94mFalse\u001b[0m,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3002 \u001b[0m\u001b[2m               \u001b[0mdesc=desc \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mMap\u001b[0m\u001b[33m\"\u001b[0m,                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3003 \u001b[0m\u001b[2m            \u001b[0m) \u001b[94mas\u001b[0m pbar:                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3004 \u001b[2m               \u001b[0m\u001b[94mfor\u001b[0m rank, done, content \u001b[95min\u001b[0m Dataset._map_single(**dataset_kwargs):     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3005 \u001b[0m\u001b[2m                  \u001b[0m\u001b[94mif\u001b[0m done:                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3006 \u001b[0m\u001b[2m                     \u001b[0mshards_done += \u001b[94m1\u001b[0m                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3007 \u001b[0m\u001b[2m                     \u001b[0mlogger.debug(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFinished processing shard number \u001b[0m\u001b[33m{\u001b[0mrank\u001b[33m}\u001b[0m\u001b[33m of \u001b[0m\u001b[33m{\u001b[0mn  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m338\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m0\u001b[0m in \u001b[92m_map_single\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3377 \u001b[0m\u001b[2m                     \u001b[0m\u001b[96mrange\u001b[0m(*(\u001b[96mslice\u001b[0m(i, i + batch_size).indices(shard.num_rows)))    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3378 \u001b[0m\u001b[2m                  \u001b[0m)  \u001b[2m# Something simpler?\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3379 \u001b[0m\u001b[2m                  \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3380 \u001b[2m                     \u001b[0mbatch = apply_function_on_filtered_inputs(                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3381 \u001b[0m\u001b[2m                        \u001b[0mbatch,                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3382 \u001b[0m\u001b[2m                        \u001b[0mindices,                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3383 \u001b[0m\u001b[2m                        \u001b[0mcheck_same_num_examples=\u001b[96mlen\u001b[0m(shard.list_indexes()) > \u001b[94m0\u001b[0m,    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m326\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m1\u001b[0m in \u001b[92mapply_function_on_filtered_inputs\u001b[0m                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3258 \u001b[0m\u001b[2m            \u001b[0madditional_args += (effective_indices,)                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3259 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m with_rank:                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3260 \u001b[0m\u001b[2m            \u001b[0madditional_args += (rank,)                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3261 \u001b[2m         \u001b[0mprocessed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3262 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(processed_inputs, LazyDict):                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3263 \u001b[0m\u001b[2m            \u001b[0mprocessed_inputs = {                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3264 \u001b[0m\u001b[2m               \u001b[0mk: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m processed_inputs.data.items() \u001b[94mif\u001b[0m k \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m processed  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92msummarize_preprocess_function\u001b[0m:\u001b[94m3\u001b[0m                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msummarize_preprocess_function\u001b[0m(article_data):                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m   \u001b[0minputs = [prefix + abstract \u001b[94mfor\u001b[0m abstract \u001b[95min\u001b[0m article_data[\u001b[33m\"\u001b[0m\u001b[33marticle\u001b[0m\u001b[33m\"\u001b[0m]]                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3 \u001b[2m   \u001b[0mmodel_inputs = tokenizer(inputs, max_length=\u001b[94m1024\u001b[0m, truncation=\u001b[94mTrue\u001b[0m)                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m   \u001b[0mlabels = tokenizer(text_target=article_data[\u001b[33m\"\u001b[0m\u001b[33mabstract\u001b[0m\u001b[33m\"\u001b[0m], max_length=\u001b[94m128\u001b[0m, truncation=     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m   \u001b[0mmodel_inputs[\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m] = labels[\u001b[33m\"\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m\"\u001b[0m]                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m6 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m model_inputs                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_uti\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mls_base.py\u001b[0m:\u001b[94m2488\u001b[0m in \u001b[92m__call__\u001b[0m                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2485 \u001b[0m\u001b[2m         \u001b[0m\u001b[2m# input mode in this case.\u001b[0m                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2486 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._in_target_context_manager:                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2487 \u001b[0m\u001b[2m            \u001b[0m\u001b[96mself\u001b[0m._switch_to_input_mode()                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2488 \u001b[2m         \u001b[0mencodings = \u001b[96mself\u001b[0m._call_one(text=text, text_pair=text_pair, **all_kwargs)      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2489 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m text_target \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2490 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m._switch_to_target_mode()                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2491 \u001b[0m\u001b[2m         \u001b[0mtarget_encodings = \u001b[96mself\u001b[0m._call_one(text=text_target, text_pair=text_pair_targ  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_uti\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mls_base.py\u001b[0m:\u001b[94m2574\u001b[0m in \u001b[92m_call_one\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2571 \u001b[0m\u001b[2m               \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlen\u001b[0m(text_pair)\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\"\u001b[0m                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2572 \u001b[0m\u001b[2m            \u001b[0m)                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2573 \u001b[0m\u001b[2m         \u001b[0mbatch_text_or_text_pairs = \u001b[96mlist\u001b[0m(\u001b[96mzip\u001b[0m(text, text_pair)) \u001b[94mif\u001b[0m text_pair \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2574 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.batch_encode_plus(                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2575 \u001b[0m\u001b[2m            \u001b[0mbatch_text_or_text_pairs=batch_text_or_text_pairs,                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2576 \u001b[0m\u001b[2m            \u001b[0madd_special_tokens=add_special_tokens,                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2577 \u001b[0m\u001b[2m            \u001b[0mpadding=padding,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_uti\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mls_base.py\u001b[0m:\u001b[94m2765\u001b[0m in \u001b[92mbatch_encode_plus\u001b[0m                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2762 \u001b[0m\u001b[2m         \u001b[0m**kwargs,                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2763 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2764 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2765 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._batch_encode_plus(                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2766 \u001b[0m\u001b[2m         \u001b[0mbatch_text_or_text_pairs=batch_text_or_text_pairs,                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2767 \u001b[0m\u001b[2m         \u001b[0madd_special_tokens=add_special_tokens,                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2768 \u001b[0m\u001b[2m         \u001b[0mpadding_strategy=padding_strategy,                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_uti\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mls_fast.py\u001b[0m:\u001b[94m429\u001b[0m in \u001b[92m_batch_encode_plus\u001b[0m                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m426 \u001b[0m\u001b[2m         \u001b[0mpad_to_multiple_of=pad_to_multiple_of,                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m427 \u001b[0m\u001b[2m      \u001b[0m)                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m428 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m429 \u001b[2m      \u001b[0mencodings = \u001b[96mself\u001b[0m._tokenizer.encode_batch(                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m430 \u001b[0m\u001b[2m         \u001b[0mbatch_text_or_text_pairs,                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m431 \u001b[0m\u001b[2m         \u001b[0madd_special_tokens=add_special_tokens,                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m432 \u001b[0m\u001b[2m         \u001b[0mis_pretokenized=is_split_into_words,                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_arxiv_summarization = arxiv_summarization.map(summarize_preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0127d428947c40c48b903c2745a84cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e5bc1d01d54165a968da3410c6e2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/transformers/modeling_utils.py:386: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/torch/_utils.py:777: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/torch/storage.py:955: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/safetensors/torch.py:98: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"arxiv_summarization_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>trainer = Seq2SeqTrainer(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2    </span>model=model,                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3    </span>args=training_args,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 4 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>train_dataset=tokenized_arxiv_summarization[<span style=\"color: #808000; text-decoration-color: #808000\">\"train\"</span>],                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5    </span>eval_dataset=tokenized_arxiv_summarization[<span style=\"color: #808000; text-decoration-color: #808000\">\"test\"</span>],                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6    </span>tokenizer=tokenizer,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7    </span>data_collator=data_collator,                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">270</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2706    </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2707    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, key):  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># noqa: F811</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2708 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Can be used to index columns (by string names) or rows (by integer index or i</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2709 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem(key)                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2710    </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2711    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitems__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, keys: List) -&gt; List:                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2712 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"</span>                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">269</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_getitem</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2690       </span>format_kwargs = kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"format_kwargs\"</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"format_kwargs\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> kwargs <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2691       </span>format_kwargs = format_kwargs <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> format_kwargs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> {}                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2692       </span>formatter = get_formatter(format_type, features=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._info.features, **format_kw  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2693 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>pa_subtable = query_table(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data, key, indices=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._indices <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._indice  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2694       </span>formatted_output = format_table(                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2695          </span>pa_subtable, key, formatter=formatter, format_columns=format_columns, output  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2696       </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/formatting/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">formattin</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">g.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">585</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">query_table</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">582    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(key, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">slice</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, Iterable)):                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">583       </span>_raise_bad_key_type(key)                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">584    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(key, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>585 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>_check_valid_column_key(key, table.column_names)                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">586    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">587       </span>size = indices.num_rows <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> indices <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> table.num_rows                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">588       </span>_check_valid_index_key(key, size)                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/formatting/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">formattin</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">g.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">525</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_valid_column_key</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">522 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">523 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_valid_column_key</span>(key: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, columns: List[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>]) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">524    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> columns:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>525 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Column {</span>key<span style=\"color: #808000; text-decoration-color: #808000\">} not in the dataset. Current columns in the dataset</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">526 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">527 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">528 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_check_valid_index_key</span>(key: Union[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">slice</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>, Iterable], size: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Column train not in the dataset. Current columns in the dataset: ['article', 'abstract', 'input_ids', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask', 'labels']\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 1 \u001b[0mtrainer = Seq2SeqTrainer(                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m   \u001b[0mmodel=model,                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m   \u001b[0margs=training_args,                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 4 \u001b[2m   \u001b[0mtrain_dataset=tokenized_arxiv_summarization[\u001b[33m\"\u001b[0m\u001b[33mtrain\u001b[0m\u001b[33m\"\u001b[0m],                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m   \u001b[0meval_dataset=tokenized_arxiv_summarization[\u001b[33m\"\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m\"\u001b[0m],                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m   \u001b[0mtokenizer=tokenizer,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m   \u001b[0mdata_collator=data_collator,                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m270\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m9\u001b[0m in \u001b[92m__getitem__\u001b[0m                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2706 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2707 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getitem__\u001b[0m(\u001b[96mself\u001b[0m, key):  \u001b[2m# noqa: F811\u001b[0m                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2708 \u001b[0m\u001b[2;90m      \u001b[0m\u001b[33m\"\"\"Can be used to index columns (by string names) or rows (by integer index or i\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2709 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem(key)                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2710 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2711 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getitems__\u001b[0m(\u001b[96mself\u001b[0m, keys: List) -> List:                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2712 \u001b[0m\u001b[2;90m      \u001b[0m\u001b[33m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[0m                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m269\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[94m3\u001b[0m in \u001b[92m_getitem\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2690 \u001b[0m\u001b[2m      \u001b[0mformat_kwargs = kwargs[\u001b[33m\"\u001b[0m\u001b[33mformat_kwargs\u001b[0m\u001b[33m\"\u001b[0m] \u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mformat_kwargs\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m kwargs \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m._  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2691 \u001b[0m\u001b[2m      \u001b[0mformat_kwargs = format_kwargs \u001b[94mif\u001b[0m format_kwargs \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m {}                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2692 \u001b[0m\u001b[2m      \u001b[0mformatter = get_formatter(format_type, features=\u001b[96mself\u001b[0m._info.features, **format_kw  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2693 \u001b[2m      \u001b[0mpa_subtable = query_table(\u001b[96mself\u001b[0m._data, key, indices=\u001b[96mself\u001b[0m._indices \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._indice  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2694 \u001b[0m\u001b[2m      \u001b[0mformatted_output = format_table(                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2695 \u001b[0m\u001b[2m         \u001b[0mpa_subtable, key, formatter=formatter, format_columns=format_columns, output  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2696 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/formatting/\u001b[0m\u001b[1;33mformattin\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mg.py\u001b[0m:\u001b[94m585\u001b[0m in \u001b[92mquery_table\u001b[0m                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m582 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(key, (\u001b[96mint\u001b[0m, \u001b[96mslice\u001b[0m, \u001b[96mrange\u001b[0m, \u001b[96mstr\u001b[0m, Iterable)):                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m583 \u001b[0m\u001b[2m      \u001b[0m_raise_bad_key_type(key)                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m584 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(key, \u001b[96mstr\u001b[0m):                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m585 \u001b[2m      \u001b[0m_check_valid_column_key(key, table.column_names)                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m586 \u001b[0m\u001b[2m   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m587 \u001b[0m\u001b[2m      \u001b[0msize = indices.num_rows \u001b[94mif\u001b[0m indices \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m table.num_rows                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m588 \u001b[0m\u001b[2m      \u001b[0m_check_valid_index_key(key, size)                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/datasets/formatting/\u001b[0m\u001b[1;33mformattin\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mg.py\u001b[0m:\u001b[94m525\u001b[0m in \u001b[92m_check_valid_column_key\u001b[0m                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m522 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m523 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_check_valid_column_key\u001b[0m(key: \u001b[96mstr\u001b[0m, columns: List[\u001b[96mstr\u001b[0m]) -> \u001b[94mNone\u001b[0m:                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m524 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m key \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m columns:                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m525 \u001b[2m      \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mColumn \u001b[0m\u001b[33m{\u001b[0mkey\u001b[33m}\u001b[0m\u001b[33m not in the dataset. Current columns in the dataset\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m526 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m527 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m528 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_check_valid_index_key\u001b[0m(key: Union[\u001b[96mint\u001b[0m, \u001b[96mslice\u001b[0m, \u001b[96mrange\u001b[0m, Iterable], size: \u001b[96mint\u001b[0m) -> \u001b[94mNone\u001b[0m:    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m\"Column train not in the dataset. Current columns in the dataset: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'article', 'abstract', 'input_ids', \u001b[0m\n",
       "\u001b[32m'attention_mask', 'labels'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_arxiv_summarization[\"train\"],\n",
    "    eval_dataset=tokenized_arxiv_summarization[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
